<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>  
    div.padded {  
      padding-top: 0px;  
      padding-right: 100px;  
      padding-bottom: 0.25in;  
      padding-left: 100px;  
    }  
  </style> 
<title>Walker Snedaker  |  CS 184</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<h1 align="middle">Assignment 3: PathTracer part 2</h1>
    <h2 align="middle">Walker Snedaker</h2>

    <div class="padded">
        <p>Overview: In this project I implemeted three major improvements that build on the previos project. The first is a set of new BSDF fucntions that allow me to render mirrored, glass, and microfaseted materials, which are things like brushed or glossy metels. Next I implemented a new lighting set up for the project which allows me to add environment lighting to scenes, creating more realistic scenes that aren't essentialy in a dark empty room. Finaly I implemented a thin lens camera model which is essentialy a model that allows the scenes I create to look as if they were taken with an actual camera, with a thin lens, focal point, and apature. These combine to allow me, with the combination of the previous projects code, create a varied amount of new scenes with interesting new lighting of the scene, materials in the schene, and focusing on said materials in the scene. </p>

            <h2 align="middle">Part 1: Mirror and Glass</h2>
            <p>In Part 1 I implemented the BSDF set up for glass objects and perfect mirror objects. First for Mirrors I implemented the BSDF by simpy taking the out going ray from the surface to be the vector in object space coordinates as the vector with negative x and y direction and the same z direction, with the specturm beign that of an ideal mirror and thus the reflectance divided by the angle from the normal. Next for Glass I implementd the BsDF by first calculating if there is total internal relfection and if these is than returning the reflection as if it is a mirror, if there is not total internal reflection I calculate Schlick's Approximation and use it as our random chance paramater to decide if the ray that impacts the surface reflects our of the surface or refracts into it. If the incoming ray refracts I use snells law to calculate the outgoing ray and finaly calculate the outgoing irradiance by taking it to be that of the reflection divided by the square of the snells law factor eta.</p>
            <p>Now lets look at the spheres scene and see how increasing the max number of bounces for each reveals interesting new multibounce effects. To start the first multibounce effect we witness is that at one bounce both the mirrored sphere and glass sphere are completely dark, while at two bounces the light has time to bounce onto the schene then onto the mirrored sphere then to the camera, but the light is still bouncing in the glass ball and has yet to move through to the camera. Then at 3 bounces we can see the glass ball as the light leaves it, now hitting the camera, but the light that bounces from the glass ball to other parts of the schene has yet to bounce to the camera, so the ball casts a shadow and is dark on the mirror. Then at 4 bounces the glass ball reflects form the mirrored ball to the camera, and the glass ball iluminates a spot on the ground as we would expect. Finaly we reach the maximum number of multibounce effects when the lights reflection of the mirrored ball makes it through the glass ball illuminating a patch on the wall. Its seen that this is the max number of effects since the 100 bounce version reveals no more effects.</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/spheres0.png" width="480px" />
                            <figcaption align="middle">CBspheres run with maxdepth 0.</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/spheres1.png" width="480px" />
                            <figcaption align="middle">CBspheres run with maxdepth 1.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/spheres2.png" width="480px" />
                            <figcaption align="middle">CBspheres run with maxdepth 2.</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/spheres3.png" width="480px" />
                            <figcaption align="middle">CBspheres run with maxdepth 3.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/spheres4.png" width="480px" />
                            <figcaption align="middle">CBspheres run with maxdepth 4.</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/spheres5.png" width="480px" />
                            <figcaption align="middle">CBspheres run with maxdepth 5.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/spheres100.png" width="480px" />
                            <figcaption align="middle">CBspheres run with maxdepth 100.</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <p> Finaly here are a few other images rendered usign the code in this seciton. </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/spheres7.png" width="480px" />
                            <figcaption align="middle">CBspheres run with maxdepth 7 and 256 samples per pixel</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/dragon.png" width="480px" />
                            <figcaption align="middle">CBdragon run with maxdepth 7 and 64 sampler per pixel.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/lucy.png" width="480px" />
                            <figcaption align="middle">CBlucy run with maxdepth 7 and 64 samples per pixel</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/lucy1.png" width="480px" />
                            <figcaption align="middle">CBlucy run with maxdepth 7 and 256 sampler per pixel.</figcaption>
                        </td>
                    </tr>
                </table>
            </div>


            <h2 align="middle">Part 2: Microfacet Matetials</h2>
            <p>In part two of this project I implemented the BSDF for Microfacet Materials. This is done by calculatign the Normal Distrabution function of the incoming and outgoing rays, the Frensel term of the incoming radiance, and the shadowing masking term (which was calculated for in the starer code), then calculating the BSDF by multiplying these together and dividing them by the four times the component of the incoming and outgoing vectors normal to the surface. Finaly to find the vector to use to calculate the incoming irradiance and the outgoing pdf from this point I implemented a random sampling method that randomly samples the theta and phi angle of the incoming vector and uses these randomized values to calculate the pdf.</p>
            <p>To calculate the Normal Distrabution I first calculated the half vector h, which is the average of the normalized average of the incoming and outgoing vectors. Then using this vectof the Normal Distrabution is given by the following function</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/f1PDF.PNG" width="480px" />
                        </td>
                    </tr>
                </table>
            </div>
            <p> Where theta h is the component of the half vector h in the same direction of the normal.</p>
            <p> Next I calculated the Frensel term using the following approximation, </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/f2.PNG" width="480px" />
                        </td>
                    </tr>
                </table>
            </div>
            <p> Where the n and k parts of said equation are the rbg base vectors of the surface, and the approximation is used for each componet of said base vectors to calculate the new specturm component in the red, green, or blue components. </p>
            <p> Finaly the incoming light vector and the pdf along said vector was calculated in the folowing way. First I gennerated two random values between zero and one and used these values to generate the half vector by finding its theta and phi values with the following formula,  </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/f3.PNG" width="480px" />
                        </td>
                    </tr>
                </table>
            </div>
            <p> In this formula r1 and r2 are the random values while alpha is the roughness of the surface. Next since the halfvector is the vector directly in the center of the incoming and outgoing vector we can calculate the incoming vecotr as 2 times the dot product of the half vector and the outgoing vector times the half vector minus the outgoing vector. Finaly with the incoming vector we calculate the pdf of the halfvector in the theta and phi direction and combine those to find the total pdf (the final formula) with the folowing fomulas: </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/p4.PNG" width="480px" />
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/p5.PNG" width="480px" />
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/p6.PNG" width="480px" />
                        </td>
                    </tr>
                </table>
            </div>
            <p> Now we vary the alpha, roughness, of the surface for CBdragon_microfacet_au.dae with 128 saqmples per pixel and 1 sample per light and see how this affects the rendered image. As we can see below as the roughness incresed from .005 to .5 the dragon becomes more opake and the image became cleaner with less interference. But as we can see the final image has little to no glossyness or reflection, while the earlier images had a large amount of glossyness and relfection. This lack of glossyness makes sense since a surface is drefined to be a perfect mirror if it has zero rougness.</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/dragon005.png" width="480px" />
                            <figcaption align="middle">CBdragon run with roughness .005.</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/dragon05.png" width="480px" />
                            <figcaption align="middle">CBdragon run with roughness .05.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/dragon25.png" width="480px" />
                            <figcaption align="middle">CBdragon run with roughness .25.</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/dragon5.png" width="480px" />
                            <figcaption align="middle">CBdragon run with roughness .5.</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <p> Next we compare the importance versus hemisphere sampling of the CBbunny_microfacet_cu.dae file with 64 samples per pixel and 1 sample per light and find that when rendered with the same number of sampler per pixel and per light the bunny run with importance sampling converges to a copper bunny with realistic glossyness and shading, while the hemisphere sampled bunny has more scatered rays and a dark non glossy surface.</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny64H.png" width="480px" />
                            <figcaption align="middle">CBbunny_microfacet_cu.dae run with hemisphere sampling.</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/bunny64I.png" width="480px" />
                            <figcaption align="middle">CBbunny_microfacet_cu.dae run with importance sampling.</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <p>Finaly I set the n and k terms of CBbunny_microfacet_cu.dae to be the known n and k constanst for chromium, not copper, and rendered said image getting a chrome colored glossy rabit.</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunnyCr.png" width="480px" />
                            <figcaption align="middle"> this is the chrome colored bunny</figcaption>
                        </td>
                    </tr>
                </table>
            </div>


            <h2 align="middle">Part 3: Environment light</h2>
            <p>In this third part of this project I implemented a scemea for environment lighting. Environment lighting places our schene in a full three dimensional space where ligh can and does come from all directions, this allows us to model schenes that exist in a space that is not just a black box like environment. This is done by settign an sphererical surface around our scene that is infinately far away and is the background for our scene. To use this environment to sample the lighting of the scene we take random samples of the environment in one of two ways, either through uniform spherical sampling or through importance sampling. Uniform spherical sampling simply takes a random sample in the sphere with equal probability, while importance sampling calculates the brightness of grid points on our sphere and assigns each grid point a probability that it will yeild an important value by how bright it is, we then sample points bassed on these probabilities. </p>
            <p> Now lets look at some images rendered in the following environment, which has the following probability density.</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/exrcap.JPG" width="480px" />
                            <figcaption align="middle"> This is the environmnet used in this part.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/probability_debug.png" width="480px" />
                            <figcaption align="middle"> This is the probabilitys of said environment.</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <p> First lets render bunny_unlit.dae with 4 samples per pixel and 64 sampler per light with both hemisphere and importance sampling. As we can see by these two images below the importance sampled image has far less noise and is much more illuminated. this makes sense since importance sampling takes more samples from the higher light density secitons of the environment and thus will result in a brighter scene if our schene has a large amount of darker non light background objects, as we can see our scene does have. </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunU64m.png" width="480px" />
                            <figcaption align="middle"> This is the uniform hemispher sampled image</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/bung4.png" width="480px" />
                            <figcaption align="middle"> This is the importance sampled image</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <p>Next lets render the bunny_microfacet_cu_unlit.dae file with 4 samples per pixel and 64 samples per light and a max of 5 bounces with both hemisphere and importance sampling. As we can see once again the importance sampling rendered an image with much less noise. This makes sense since the hemisphere sampled image should take much longer to converge. It is interesting to see that even with the small number of samples the copper bunny is starting to look matalic in the hemisphere sampling, as well it is interesting to see that much more of the copper color of the bunny is noticable with environment lighting that was scene in similar tests in part 2. </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunU64HI5.png" width="480px" />
                            <figcaption align="middle"> This is the uniform hemispher sampled image</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/bunU64I5.png" width="480px" />
                            <figcaption align="middle"> This is the importance sampled image</figcaption>
                        </td>
                    </tr>
                </table>
            </div>


            <h2 align="middle">Part 4: Depth of Field</h2>
            <p>In this final section of the project we implemented a depth of field model, which allows us to model scenes as if we are using a thin lens camera, not a pinhole camera. The main difference between these forms of cameras is that a pinhole camera allows us to view all objects in the scene with the same clearity as eachother no mater the depth, which although makes for good images is not how us normal humans see the world. The thin lens camera allows us to focus the image in our scene to a specific plane in the z axis and the surounding sphere as if we were close to these sections blurring those parts of the scene that fall out of these ranges, like a out eyes do when we focus on an object in the foreground vs the background. </p>
            <p> This new thin lens camera model allows us to adjust both the focal point of the camera, or where the camera is focused to, and the appature size of the lense, which is how much more into focus the plane of focus is compared to the rest of the image. So to start lets look at a focal stack, or a set of pictures with fixed appature size and different focal points on the  CBdragon_microfacet_au file:</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragonb01d10.png" width="800px" />
                            <figcaption align="middle"> This image has focal point before the dragon. </figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragonb01d20.png" width="800px" />
                            <figcaption align="middle"> This image has focal point on the front of the dragon.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragonb01d30.png" width="800px" />
                            <figcaption align="middle"> This image has focal point toward the back of the dragon.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragonb01d70.png" width="800px" />
                            <figcaption align="middle"> This image has a focal point far behind the dragon.</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <p>Now lets look at a sequence of for images focused to the same focal point with different appature size, till on the same CBdragon_microfacet_au file:</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragonb01d25.png" width="800px" />
                            <figcaption align="middle"> This image with appature size .01. </figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragonb05d25.png" width="800px" />
                            <figcaption align="middle"> This image with appature size .05.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragonb25d25.png" width="800px" />
                            <figcaption align="middle"> This image with appature size .25.</figcaption>
                        </td>
                    </tr>
                    <br />
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragonb50d25.png" width="800px" />
                            <figcaption align="middle"> This image with appature size .50.</figcaption>
                        </td>
                    </tr>
                </table>
            </div>



            </table>
        </o></div>
        </o></div>
</body>
</html>




